<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>心理科學基礎統計</title>
  <meta name="description" content="以開放科學為理念，為初學者編寫的統計教科書。">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="心理科學基礎統計" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="以開放科學為理念，為初學者編寫的統計教科書。" />
  <meta name="github-repo" content="SCgeeker/BasicStatistics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="心理科學基礎統計" />
  
  <meta name="twitter:description" content="以開放科學為理念，為初學者編寫的統計教科書。" />
  

<meta name="author" content="陳紹慶 Sau-Chin Chen">


<meta name="date" content="2018-09-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="intro.html">
<link rel="next" href="one-sample.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">心理科學基礎統計</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> 統計思考開門</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#emily-rosa"><i class="fa fa-check"></i><b>1.1</b> 統計思考實例：Emily Rosa的專題研究</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#jaspjamovi"><i class="fa fa-check"></i><b>1.2</b> 如何檢驗測試結果：認識JASP與jamovi的界面</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#section-1.3"><i class="fa fa-check"></i><b>1.3</b> 分析測試結果的實體：尺度與變項</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#section-1.4"><i class="fa fa-check"></i><b>1.4</b> 資料的生命：自變項與依變項</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#section-1.5"><i class="fa fa-check"></i><b>1.5</b> 資料的起源：母群與樣本</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#section-1.6"><i class="fa fa-check"></i><b>1.6</b> 描述統計：認識基礎統計量數</a><ul>
<li class="chapter" data-level="1.6.1" data-path="intro.html"><a href="intro.html#section-1.6.1"><i class="fa fa-check"></i><b>1.6.1</b> 名義尺度的集中趨勢：眾數</a></li>
<li class="chapter" data-level="1.6.2" data-path="intro.html"><a href="intro.html#section-1.6.2"><i class="fa fa-check"></i><b>1.6.2</b> 序列尺度的集中趨勢：百分位數與中位數</a></li>
<li class="chapter" data-level="1.6.3" data-path="intro.html"><a href="intro.html#section-1.6.3"><i class="fa fa-check"></i><b>1.6.3</b> 連續尺度的集中與變異趨勢：平均數、變異數與標準差</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#section-1.7"><i class="fa fa-check"></i><b>1.7</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="randomization.html"><a href="randomization.html"><i class="fa fa-check"></i><b>2</b> 機率與隨機方法</a><ul>
<li class="chapter" data-level="2.1" data-path="randomization.html"><a href="randomization.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 從案例學習機率的計算與模擬</a><ul>
<li class="chapter" data-level="2.1.1" data-path="randomization.html"><a href="randomization.html#section-2.1.1"><i class="fa fa-check"></i><b>2.1.1</b> 機率模型動畫頁面說明</a></li>
<li class="chapter" data-level="2.1.2" data-path="randomization.html"><a href="randomization.html#tt"><i class="fa fa-check"></i><b>2.1.2</b> 伯努力分佈：一位TT進行一次測試的成功率</a></li>
<li class="chapter" data-level="2.1.3" data-path="randomization.html"><a href="randomization.html#nttx"><i class="fa fa-check"></i><b>2.1.3</b> 二項分佈：n位TT進行x次測試的成功率</a></li>
<li class="chapter" data-level="2.1.4" data-path="randomization.html"><a href="randomization.html#emily"><i class="fa fa-check"></i><b>2.1.4</b> 均等分佈：Emily的事前預測</a></li>
<li class="chapter" data-level="2.1.5" data-path="randomization.html"><a href="randomization.html#section-2.1.5"><i class="fa fa-check"></i><b>2.1.5</b> 事後機率分配：估計第一次測試的成功率</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="randomization.html"><a href="randomization.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 條件機率的計算與模擬</a><ul>
<li class="chapter" data-level="2.2.1" data-path="randomization.html"><a href="randomization.html#section-2.2.1"><i class="fa fa-check"></i><b>2.2.1</b> 從蒙提霍爾問題理解貝氏定理</a></li>
<li class="chapter" data-level="2.2.2" data-path="randomization.html"><a href="randomization.html#tt"><i class="fa fa-check"></i><b>2.2.2</b> 使用事後機率推測TT的能力</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="randomization.html"><a href="randomization.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 統計學兩大流派</a><ul>
<li class="chapter" data-level="2.3.1" data-path="randomization.html"><a href="randomization.html#section-2.3.1"><i class="fa fa-check"></i><b>2.3.1</b> 次數主義統計</a></li>
<li class="chapter" data-level="2.3.2" data-path="randomization.html"><a href="randomization.html#section-2.3.2"><i class="fa fa-check"></i><b>2.3.2</b> 貝氏統計</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="randomization.html"><a href="randomization.html#-1"><i class="fa fa-check"></i><b>2.4</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="one-sample.html"><a href="one-sample.html"><i class="fa fa-check"></i><b>3</b> 這個分數是我要的嗎？單一樣本平均數假設檢定</a><ul>
<li class="chapter" data-level="3.1" data-path="one-sample.html"><a href="one-sample.html#section-3.1"><i class="fa fa-check"></i><b>3.1</b> 為何行為科學不常見到完整的母群？</a></li>
<li class="chapter" data-level="3.2" data-path="one-sample.html"><a href="one-sample.html#section-3.2"><i class="fa fa-check"></i><b>3.2</b> 母群變異數未知的抽樣分配</a><ul>
<li class="chapter" data-level="3.2.1" data-path="one-sample.html"><a href="one-sample.html#section-3.2.1"><i class="fa fa-check"></i><b>3.2.1</b> 點估計是隨機的</a></li>
<li class="chapter" data-level="3.2.2" data-path="one-sample.html"><a href="one-sample.html#t"><i class="fa fa-check"></i><b>3.2.2</b> 認識t分佈</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="one-sample.html"><a href="one-sample.html#section-3.3"><i class="fa fa-check"></i><b>3.3</b> 單一樣本平均數的假設檢定</a><ul>
<li class="chapter" data-level="3.3.1" data-path="one-sample.html"><a href="one-sample.html#section-3.3.1"><i class="fa fa-check"></i><b>3.3.1</b> 分析前的宣告</a></li>
<li class="chapter" data-level="3.3.2" data-path="one-sample.html"><a href="one-sample.html#section-3.3.2"><i class="fa fa-check"></i><b>3.3.2</b> 示範檔案操作說明</a></li>
<li class="chapter" data-level="3.3.3" data-path="one-sample.html"><a href="one-sample.html#section-3.3.3"><i class="fa fa-check"></i><b>3.3.3</b> 示範檔案報表解讀</a></li>
<li class="chapter" data-level="3.3.4" data-path="one-sample.html"><a href="one-sample.html#section-3.3.4"><i class="fa fa-check"></i><b>3.3.4</b> 分析後報告</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="one-sample.html"><a href="one-sample.html#p"><i class="fa fa-check"></i><b>3.4</b> p值是什麼？</a></li>
<li class="chapter" data-level="3.5" data-path="one-sample.html"><a href="one-sample.html#section-3.5"><i class="fa fa-check"></i><b>3.5</b> 效果量與考驗力</a></li>
<li class="chapter" data-level="3.6" data-path="one-sample.html"><a href="one-sample.html#-2"><i class="fa fa-check"></i><b>3.6</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ci.html"><a href="ci.html"><i class="fa fa-check"></i><b>4</b> 這個分數是我要的嗎？單一樣本平均數的信賴區間</a><ul>
<li class="chapter" data-level="4.1" data-path="ci.html"><a href="ci.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 信賴區間的計算與報告</a></li>
<li class="chapter" data-level="4.2" data-path="ci.html"><a href="ci.html#section-4.2"><i class="fa fa-check"></i><b>4.2</b> 信賴區間的機率本質</a></li>
<li class="chapter" data-level="4.3" data-path="ci.html"><a href="ci.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 信賴區間與研究結果可再現性</a></li>
<li class="chapter" data-level="4.4" data-path="ci.html"><a href="ci.html#section-4.4"><i class="fa fa-check"></i><b>4.4</b> 治療性撫慰師真有本事嗎？</a></li>
<li class="chapter" data-level="4.5" data-path="ci.html"><a href="ci.html#-3"><i class="fa fa-check"></i><b>4.5</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="two-samples.html"><a href="two-samples.html"><i class="fa fa-check"></i><b>5</b> 我的分數比你的分數高嗎？相依樣本與獨立樣本</a><ul>
<li class="chapter" data-level="5.1" data-path="two-samples.html"><a href="two-samples.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 型一錯誤與型二錯誤</a></li>
<li class="chapter" data-level="5.2" data-path="two-samples.html"><a href="two-samples.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 示範資料說明</a></li>
<li class="chapter" data-level="5.3" data-path="two-samples.html"><a href="two-samples.html#section-5.3"><i class="fa fa-check"></i><b>5.3</b> 相依樣本與重覆量數</a><ul>
<li class="chapter" data-level="5.3.1" data-path="randomization.html"><a href="randomization.html#-1"><i class="fa fa-check"></i><b>5.3.1</b> 分析前的宣告</a></li>
<li class="chapter" data-level="5.3.2" data-path="randomization.html"><a href="randomization.html#-1"><i class="fa fa-check"></i><b>5.3.2</b> 示範檔案操作說明</a></li>
<li class="chapter" data-level="5.3.3" data-path="randomization.html"><a href="randomization.html#-1"><i class="fa fa-check"></i><b>5.3.3</b> 示範檔案報表解讀</a></li>
<li class="chapter" data-level="5.3.4" data-path="randomization.html"><a href="randomization.html#-1"><i class="fa fa-check"></i><b>5.3.4</b> 分析後報告</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="two-samples.html"><a href="two-samples.html#section-5.4"><i class="fa fa-check"></i><b>5.4</b> 獨立樣本與組間比較</a><ul>
<li class="chapter" data-level="5.4.1" data-path="one-sample.html"><a href="one-sample.html#-2"><i class="fa fa-check"></i><b>5.4.1</b> 分析前的宣告</a></li>
<li class="chapter" data-level="5.4.2" data-path="one-sample.html"><a href="one-sample.html#-2"><i class="fa fa-check"></i><b>5.4.2</b> 示範檔案操作說明</a></li>
<li class="chapter" data-level="5.4.3" data-path="one-sample.html"><a href="one-sample.html#-2"><i class="fa fa-check"></i><b>5.4.3</b> 示範檔案報表解讀</a></li>
<li class="chapter" data-level="5.4.4" data-path="one-sample.html"><a href="one-sample.html#-2"><i class="fa fa-check"></i><b>5.4.4</b> 分析後報告</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="one-sample.html"><a href="one-sample.html#p"><i class="fa fa-check"></i><b>5.5</b> 效果量、p值與考驗力</a></li>
<li class="chapter" data-level="5.6" data-path="two-samples.html"><a href="two-samples.html#section-5.6"><i class="fa fa-check"></i><b>5.6</b> 如何提高實驗結果的再現性？</a></li>
<li class="chapter" data-level="5.7" data-path="two-samples.html"><a href="two-samples.html#-4"><i class="fa fa-check"></i><b>5.7</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="corr.html"><a href="corr.html"><i class="fa fa-check"></i><b>6</b> 我倆多有緣？相關與迴歸</a><ul>
<li class="chapter" data-level="6.1" data-path="corr.html"><a href="corr.html#iris"><i class="fa fa-check"></i><b>6.1</b> Iris資料介紹</a></li>
<li class="chapter" data-level="6.2" data-path="corr.html"><a href="corr.html#iris"><i class="fa fa-check"></i><b>6.2</b> Iris相關分析</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ci.html"><a href="ci.html#-3"><i class="fa fa-check"></i><b>6.2.1</b> 分析前的宣告</a></li>
<li class="chapter" data-level="6.2.2" data-path="ci.html"><a href="ci.html#-3"><i class="fa fa-check"></i><b>6.2.2</b> 示範檔案操作說明</a></li>
<li class="chapter" data-level="6.2.3" data-path="ci.html"><a href="ci.html#-3"><i class="fa fa-check"></i><b>6.2.3</b> 示範檔案報表解讀</a></li>
<li class="chapter" data-level="6.2.4" data-path="ci.html"><a href="ci.html#-3"><i class="fa fa-check"></i><b>6.2.4</b> 分析後報告</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="corr.html"><a href="corr.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 均值迴歸</a></li>
<li class="chapter" data-level="6.4" data-path="corr.html"><a href="corr.html#iris"><i class="fa fa-check"></i><b>6.4</b> Iris迴歸分析</a><ul>
<li class="chapter" data-level="6.4.1" data-path="two-samples.html"><a href="two-samples.html#-4"><i class="fa fa-check"></i><b>6.4.1</b> 分析前的宣告</a></li>
<li class="chapter" data-level="6.4.2" data-path="two-samples.html"><a href="two-samples.html#-4"><i class="fa fa-check"></i><b>6.4.2</b> 示範檔案操作說明</a></li>
<li class="chapter" data-level="6.4.3" data-path="two-samples.html"><a href="two-samples.html#-4"><i class="fa fa-check"></i><b>6.4.3</b> 示範檔案報表解讀</a></li>
<li class="chapter" data-level="6.4.4" data-path="two-samples.html"><a href="two-samples.html#-4"><i class="fa fa-check"></i><b>6.4.4</b> 分析後報告</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="corr.html"><a href="corr.html#-5"><i class="fa fa-check"></i><b>6.5</b> 習題</a><ul>
<li class="chapter" data-level="6.5.1" data-path="corr.html"><a href="corr.html#big-5"><i class="fa fa-check"></i><b>6.5.1</b> Big 5人格量表分析</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="oneway-anova.html"><a href="oneway-anova.html"><i class="fa fa-check"></i><b>7</b> 如何比較同班同學的分數？獨立樣本單因子變異數分析</a><ul>
<li class="chapter" data-level="7.1" data-path="oneway-anova.html"><a href="oneway-anova.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 比較多組平均數有何不同？</a><ul>
<li class="chapter" data-level="7.1.1" data-path="one-sample.html"><a href="one-sample.html#t"><i class="fa fa-check"></i><b>7.1.1</b> 為何t檢定會低估型一錯誤率</a></li>
<li class="chapter" data-level="7.1.2" data-path="oneway-anova.html"><a href="oneway-anova.html#section-7.1.2"><i class="fa fa-check"></i><b>7.1.2</b> 效果量家族</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="oneway-anova.html"><a href="oneway-anova.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 分解變異數來源</a></li>
<li class="chapter" data-level="7.3" data-path="oneway-anova.html"><a href="oneway-anova.html#section-7.3"><i class="fa fa-check"></i><b>7.3</b> 獨立樣本變異數分析示範</a><ul>
<li class="chapter" data-level="7.3.1" data-path="corr.html"><a href="corr.html#-5"><i class="fa fa-check"></i><b>7.3.1</b> 分析前的宣告</a></li>
<li class="chapter" data-level="7.3.2" data-path="corr.html"><a href="corr.html#-5"><i class="fa fa-check"></i><b>7.3.2</b> 示範檔案操作說明</a></li>
<li class="chapter" data-level="7.3.3" data-path="corr.html"><a href="corr.html#-5"><i class="fa fa-check"></i><b>7.3.3</b> 示範檔案報表解讀</a></li>
<li class="chapter" data-level="7.3.4" data-path="corr.html"><a href="corr.html#-5"><i class="fa fa-check"></i><b>7.3.4</b> 分析後報告</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="oneway-anova.html"><a href="oneway-anova.html#section-7.4"><i class="fa fa-check"></i><b>7.4</b> 變異數分析的考驗力</a></li>
<li class="chapter" data-level="7.5" data-path="oneway-anova.html"><a href="oneway-anova.html#-6"><i class="fa fa-check"></i><b>7.5</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="twoway-anova.html"><a href="twoway-anova.html"><i class="fa fa-check"></i><b>8</b> 如何比較各班同學的分數？獨立樣本二因子變異數分析</a><ul>
<li class="chapter" data-level="8.1" data-path="twoway-anova.html"><a href="twoway-anova.html#c"><i class="fa fa-check"></i><b>8.1</b> 示範案例：有效攝取維他命C的方式</a><ul>
<li class="chapter" data-level="8.1.1" data-path="oneway-anova.html"><a href="oneway-anova.html#-6"><i class="fa fa-check"></i><b>8.1.1</b> 分析前的宣告</a></li>
<li class="chapter" data-level="8.1.2" data-path="oneway-anova.html"><a href="oneway-anova.html#-6"><i class="fa fa-check"></i><b>8.1.2</b> 示範檔案操作說明</a></li>
<li class="chapter" data-level="8.1.3" data-path="oneway-anova.html"><a href="oneway-anova.html#-6"><i class="fa fa-check"></i><b>8.1.3</b> 示範檔案報表解讀</a></li>
<li class="chapter" data-level="8.1.4" data-path="oneway-anova.html"><a href="oneway-anova.html#-6"><i class="fa fa-check"></i><b>8.1.4</b> 分析後報告</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="twoway-anova.html"><a href="twoway-anova.html#section-8.2"><i class="fa fa-check"></i><b>8.2</b> 獨變項是不是隨機的？</a><ul>
<li class="chapter" data-level="8.2.1" data-path="twoway-anova.html"><a href="twoway-anova.html#section-8.2.1"><i class="fa fa-check"></i><b>8.2.1</b> 交互作用的考驗力</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="twoway-anova.html"><a href="twoway-anova.html#-7"><i class="fa fa-check"></i><b>8.3</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="non-para.html"><a href="non-para.html"><i class="fa fa-check"></i><b>9</b> 沒有母群如何比高低？無母數統計</a><ul>
<li class="chapter" data-level="9.1" data-path="non-para.html"><a href="non-para.html#section-9.1"><i class="fa fa-check"></i><b>9.1</b> 母數統計的基本條件</a></li>
<li class="chapter" data-level="9.2" data-path="non-para.html"><a href="non-para.html#section-9.2"><i class="fa fa-check"></i><b>9.2</b> 獨立樣本的無母數統計：卡方檢定</a><ul>
<li class="chapter" data-level="9.2.1" data-path="intro.html"><a href="intro.html#emily-rosa"><i class="fa fa-check"></i><b>9.2.1</b> 適合度考驗：重新檢視Emily Rosa的資料</a></li>
<li class="chapter" data-level="9.2.2" data-path="non-para.html"><a href="non-para.html#rogersmilkman2016"><i class="fa fa-check"></i><b>9.2.2</b> 獨立性考驗：重製Rogers與Milkman(2016)的分析</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="non-para.html"><a href="non-para.html#section-9.3"><i class="fa fa-check"></i><b>9.3</b> 其他基礎無母數統計</a><ul>
<li class="chapter" data-level="9.3.1" data-path="non-para.html"><a href="non-para.html#section-9.3.1"><i class="fa fa-check"></i><b>9.3.1</b> 獨立樣本與相依樣本的無母數統計</a></li>
<li class="chapter" data-level="9.3.2" data-path="non-para.html"><a href="non-para.html#section-9.3.2"><i class="fa fa-check"></i><b>9.3.2</b> 變異數分析的無母數統計</a></li>
<li class="chapter" data-level="9.3.3" data-path="non-para.html"><a href="non-para.html#section-9.3.3"><i class="fa fa-check"></i><b>9.3.3</b> 相關分析的無母數統計</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="non-para.html"><a href="non-para.html#-8"><i class="fa fa-check"></i><b>9.4</b> 習題</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="e58f83e88083e69687e78dbb.html"><a href="e58f83e88083e69687e78dbb.html"><i class="fa fa-check"></i>參考文獻</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">本書以bookdown編輯</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">心理科學基礎統計</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="randomization" class="section level1">
<h1><span class="header-section-number">第2單元</span> 機率與隨機方法</h1>
<p>第<a href="intro.html#intro">1</a>單元的最後，我們示範分析2010年美國一般社會調查的部分資料<span class="citation">(T. W. Smith, Marsden, Hout, &amp; Kim, n.d.)</span>。這種資料是用<strong>隨機方法從母群抽取樣本</strong>的分析結果，讓我們能用統計方法分析其中資訊，並以此以宣稱調查結果顯示2010年美國社會的狀況。研究者能在報告寫出可靠的結論，是根據數學家發現的<strong>機率模型</strong>與統計學家創造的應用方法，讓我們能轉化問題為統計思考的命題，分析資料檢驗結論的可靠性。</p>
<p>第<a href="intro.html#intro">1</a>單元也提到Emily Rosa驗證治療性撫慰師能力的研究，這個單元我們將從這個研究案，學習如何運用<strong>機率</strong>與<strong>隨機方法</strong>，根據測試資料推測參與研究的治療性撫慰師們，隔空感應人體能量場的真實能力。我們會學習到什麼是<strong>計算的機率</strong>與<strong>模擬的機率</strong>；在Emily的案例裡，我們將了解為何<strong>均勻分佈</strong>能估計撫慰師們的能力？為何<strong>二項分佈</strong>能呈現判斷撫慰師真實能力的標準？為何隨機方法能結合均勻分佈與二項分佈？</p>
<p>為了讓學生了解<strong>計算的機率</strong>與<strong>模擬的機率</strong>在統計分析實務展現的功能，這個單元的操作示範都是使用jamovi。因為模擬機率分配需要使用R程式碼，請讀者開啟這個單元提供的示範檔案之前，確認個人使用的jamovi版本是0.9以上，並且已經安裝<code>Rj</code>(Editor to run R code inside jamovi)模組。 <!---
這個單元使用視覺化範例，介紹隨機方法的重要原理。我們會取用史丹福大學研究生Daniel Kunin[-@KuninSeeingTheory2016]創作的網站seeing thoery，說明重要的觀念與原理。因為有視覺化材料，如果你是對數學沒有信心的初學者，不必先了解機率模型的數學公式，也能了解面對什麼問題要使用那種機率模型。**但是請注意，未來有需要進階時，還是要認識機率模型的數學原理，這個單元只是機率學的基本入門。**

這個單元多數示範分析是jamovi，因為jamovi的`計算變項`有資料函數功能，搭配視覺化範例的模擬資料分析，與真實資料分析，能讓你更了解第\@ref(intro)單元所提的統計量數應用原則。
---></p>
<!---
## 隨機變數與簡單抽樣

### 認識隨機抽樣

<iframe 
    src="https://students.brown.edu/seeing-theory/probability-distributions/index.html#section1" 
    width="100%" 
    height="800px" 
    scrolling="no"
    style="margin-top: 15px;margin-bottom: 15px;"
    frameborder="1">
</iframe>

我們從[隨機變數示範網頁](https://students.brown.edu/seeing-theory/probability-distributions/index.html#section1)開始。這個網頁的設計目的是讓你動手做你想做的**隨機抽樣模擬**：隨機抽樣就像有一隻蜜蜂回到蜂巢，從那個孔進入裡面是**隨機的**。按下左方最下面的`sample distribution`之前，你可以先把蜂巢分成幾個區塊，只要先在你先點擊你選好的六角形使其變色，再於左方頁的對話框給一個值，按下`submit`剛點過的區域就會變色，並給予一個值。為了方便說明，我做了一個像圖\@ref(fig:random-variables-01)的兩個區塊，剛好將整個蜂巢分成兩半。

<div class="figure" style="text-align: center">
<img src="images/random-variable-1before.jpg" alt="Random Variable示範頁面的區域劃分示範。" width="50%" />
<p class="caption">(\#fig:random-variables-01)Random Variable示範頁面的區域劃分示範。</p>
</div>

完成後按一下左方頁面最下面的`sample distribution`，你會看到兩個頁面都有跑動畫。右邊頁面模擬蜜蜂出巢，左邊頁面有長條圖逐漸形成。長條圖即時紀錄蜜蜂從那一的區塊出去，因為先這定了兩塊，所以有兩條長條持續增高。

圖\@ref(fig:random-variables-02)是我自己跑了約十秒鐘動畫的結果。如果你做了和我相同的設定，也跑了一次十秒鐘的模擬，結果雖然不完全相同，但是應該非常接近。而這個結果有沒有讓你想到第\@ref(intro)單元的投擲一美元的實驗結果？沒錯，這兩個示範都是模擬同一種隨機程序，儘管問題脈絡不一樣，兩個示範裡的變項，都只有兩種數值：正面與反面；區塊0與區塊1。而蜂巢模擬更讓我們看清楚機率事件的本質：每個數值代表的事件，可以在開始啟動隨機程序之前，設定發生的可能性。如果把區塊1面積減少到整個牆面的1/4，你會發現模擬結果會是區塊0約0.75，區塊1約0.25。所以，**就算我們事先不了解區塊面積比例，以隨機程序收集足夠的樣本，我們能從試驗結果推測蜂巢的版圖分佈。**

<div class="figure" style="text-align: center">
<img src="images/random-variable-1after.jpg" alt="Random Variable示範頁面的模擬結果。" width="50%" />
<p class="caption">(\#fig:random-variables-02)Random Variable示範頁面的模擬結果。</p>
</div>

你可以嘗試改變蜂巢版圖的設定，像是區塊的排列方式，或是增加更多的區塊。接著你會發現模擬結果都與區塊面積比例一致，因為從機率的角度來看，母群是**預設測量結果的機率分佈**，而樣本是**有系統紀錄隨機事件所呈現的次數分配**。

在心理科學，許多課題的**預期機率分佈**並不明確，甚至研究者自己都不知道，但還是可以設定依變項的每個數值，發生機率是相等的。以此前提設計觀察情境、問卷項目、實驗分組等等，再以樣本資料推測我們預期的某個事件，發生機率有沒有大於或小於其他事件。以累積次數推論發生機率的統計方法，是由統計學者Jerzy Neyman與Egon Pearson共同奠基，現在被稱為**次數主義統計學(Frequentism Statistics)**。

--->
<div id="section-2.1" class="section level2">
<h2><span class="header-section-number">2.1</span> 從案例學習機率的計算與模擬</h2>
<p>首先請讀者區別兩個名詞：<strong>機率分佈</strong>與<strong>機率分配</strong>，對應的英文詞都是probability distribution，兩種中文名詞亦在各種書籍與論文使用。本書使用<strong>機率分佈</strong>的狀況是在說明如何計算有限事件的出現機率，是以法則計算或用數學公式推導，能直接用紙筆計算，也可以用R程式碼表現；<strong>機率分配</strong>是根據機率模型模擬預期事件的出現次數，必須使用程式碼操作計算機，產生模擬結果。</p>
<!---
有了母群是**預設測量結果的機率分佈**這樣的觀念，我們可以親手操作[seeing theory的機率模型動畫範例](https://students.brown.edu/seeing-theory/probability-distributions/index.html#section2)，**解剖**心理科學常遇到的**機率模型**。首先盤點第\@(intro)單元到現在，我們遇過的分析範例：(1)測試治療性撫慰師的真實能力；(2)投擲一美元硬幣試驗；(3)分析gss2010部分變項。前兩種範例剛好對應兩種間斷隨機變數：**二項分佈(Binomial Distribution)**與**伯努力分佈(Bernoulli Distribuion)**。gss2010的一部分變項是連續尺度，用這些變項來認識三種連續隨機變數：**均等分佈(uniform distribution)**以及**常態分佈(normal distribution)**。
--->
<div id="section-2.1.1" class="section level3">
<h3><span class="header-section-number">2.1.1</span> 機率模型動畫頁面說明</h3>
<iframe src="https://students.brown.edu/seeing-theory/probability-distributions/index.html#section2" width="100%" height="800px" scrolling="no" style="margin-top: 15px;margin-bottom: 15px;" frameborder="1">
</iframe>
<p><a href="https://students.brown.edu/seeing-theory/probability-distributions/index.html#section2">機率模型的動畫網頁</a>展示本書會提到的各種<strong>機率分佈</strong>，網頁能顯示特定範圍內的機率事件，使用者可對照網頁備註中的公式，從顯示為黃色線條及陰影的<strong>機率密度函數(probability density function)</strong>，了解如何計算對應事件的機率。也能由橘色展示的<strong>累積分佈函數(Cumulative distribution function)</strong>，得知一定範圍內事牛的累積發生機率。之後需要讀者仔細檢視機率分佈的地方，會有提示依照描述的條件，親自操作動畫網頁。</p>
<p>為了讓讀者親手探索Emily的研究過程，請先下載<a href="https://osf.io/7ygp4/">jamovi示範存檔</a>。這個存檔必須以jamovi 0.9以上版本才能開啟，並請讀者先確認自己的jamovi已經安裝<code>Rj</code>套件。</p>
<!---
，你可以從左方頁面選擇間斷(discrete)或連續(continuous)，再從下拉選單選擇你想剖析的機率模型，整個網頁就會切換為你選擇的模型動畫。右方網頁預設顯示的黃色線條及陰影是**機率密度函數(probability density function)**的視覺化，下方可移動的橘色按鈕是展示**累積分佈函數(Cumulative distribution function)**，稍後會說明為何設計成可移動。所有機率模型都有*機率密度函數*與*累積分佈函數*，右方頁面座標圖的橫軸顯示**機率模型可輸入的數值**，從畫面差異可看到間斷隨機變數與連續隨機變數的不同，以及為何間斷尺度資料與連續尺度資料分別使用長條圖與直方圖呈現的關鍵。座標圖的縱軸顯示的數值，一律是從0到1，表示**機率模型輸出的機率密度**。

選定要呈現的機率模型，左方頁面下方會出現**機率密度函數**的數學公式，以及機率模型的**平均數(Mean)**及**變異數(Variance)**。最下面會出現可調整的參數，以下解說為何這種機率模型有這些參數可以調整，還有調整後動畫呈現的意義。
--->
</div>
<div id="tt" class="section level3">
<h3><span class="header-section-number">2.1.2</span> 伯努力分佈：一位TT進行一次測試的成功率</h3>
<p>假想Emily Rosa還未想出她的實驗方法之前，任何一位TT要宣傳自己的能力，或者任何一位民眾想證實某位TT的能力，最直接的證實方法是看這位TT執行治療的成功率，有沒有達到宣稱的水準。如果TT的能量場理論是正確的，沒有受過訓練的一般人成功率大約是50%，受過訓練的TT有80%以上的成功率。這些狀況能使用<strong>伯努力分佈</strong>展示，我們先使用<a href="https://students.brown.edu/seeing-theory/probability-distributions/index.html#section2">機率模型的動畫網頁</a>的<code>Bernoulli random variable</code>，看看TT與一般人感應能量場成功率的差異。</p>
<blockquote>
<p>打開預設畫面你看到的只有0與1兩個數值，我們設定1代表感應成功，0代表感應失敗。參數<code>p</code>決定1的出現機率，也就是成功率；而0的出現機率就是失敗率，剛好是<span class="math inline">\(1-p\)</span>。調整左側視窗最下面的<code>p</code>，可以改變伯努力分佈的<strong>機率密度函數</strong>。<code>p</code>調整為0.5就是一般人感應能量場的成功率，0.8就是受過訓練的TT應該有的成功率。拉動橘色按鈕，還可以看到<strong>累積分佈函數</strong>是0與1機率的逐步疊加。因為只有兩個數值，所以只有從0到1兩步疊加就到頂點。</p>
</blockquote>
<p>Emily研究的<a href="https://osf.io/7ygp4/">jamovi示範存檔</a>有一段R程式碼，呈現成功率是10%到100%十種人士的伯努力分佈。實際測試則需要累積多次紀錄，比如說一萬次，計算實際的成功率。要了解實際成功率與計算得知的機率相差多少，除了做一次真正的實驗，就是運用模擬，看看<strong>機率分配</strong>與伯努力分佈的差異。jamovi示範有一行R程式碼，使用<code>p</code>為0.8的伯努力分佈模擬一萬次測試，得到的成功率。每次執行結果都會不一樣，不過都與0.8相差不大。請執行伯努力分佈與分配的程式碼幾次，了解機率計算與模擬的不同。</p>
<p>然而真的找來找一位TT，按照Emily設計的測試方法做一萬次，其實想一想有許多不可行之處。第一點，找一個人來做一萬次這樣的測試不知道要做多久？再者受測者與施測者不可能不間斷地做一萬次測試，否則測試結果必定有偏誤。所以Emily想出的設計並非根據伯努力分佈，不過伯努力分佈是很簡單的機率分佈，模擬的機率分配也很容易用任何你會操作方法重現。</p>
</div>
<div id="nttx" class="section level3">
<h3><span class="header-section-number">2.1.3</span> 二項分佈：n位TT進行x次測試的成功率</h3>
<p>Emily的論文記載的方法是找來十幾位TT，請每位做十次測試。由於每次測試都是擲硬幣決定要測試的手，所以這場實驗的隨機程序與可能的結果，都可以用二項分佈計算。我們先使用<a href="https://students.brown.edu/seeing-theory/probability-distributions/index.html#section2">機率模型的動畫網頁</a>的<code>binomial random variable</code>，了解一般人與TT的表現差異。</p>
<blockquote>
<p>打開預設畫面你看到6個數值：0,1,2,3,4,5，這是由參數<code>n</code>設定，這個數值表示一次實驗的測試次數，只要調整為10，就符合Emily的TT測試設定。參數<code>p</code>是受測者的成功率，預設的0.5代表一般人，把座標圖縮放到適當尺寸，就會看到答對5次的機率最高。如果一位TT有0.8的成功率，將參數<code>p</code>改為0.8，就會看到答對8次的機率最高。請留意，無論是那一種測試者，二項分佈的<strong>機率密度函數</strong>計算的最大機率都不到0.3，因為這個機率值是多次實驗最可能的結果，有最大機率的參數<code>n</code>稱為<strong>期望值</strong>。</p>
</blockquote>
<blockquote>
<p>拉動橘色按鈕，你會看到<em>累積分佈函數</em>從數值1開始疊加到最後一個數值。疊加的幅度與數值的出現機率成正比，所以你會看到數值5之前的幅度較大。如果你改變參數<em>p</em>，像是認為TT真有本事，p應該到少等於0.8。調整完你會看到除了數值8的出現機率最高，<em>累積分佈函數</em>的疊加幅度也是到數值8為最高。</p>
</blockquote>
<p>在這裡我們可以理解左方頁面的<strong>平均數</strong>與<strong>變異數</strong>的意義。請先重新調整二項分佈的參數：<code>n</code>等於10，<code>p</code>等於.5，你會注意到這個設定的平均數是5，也就是兩個參數的乘積，累積機率也是0.5。所以<strong>平均數</strong>是這個設定的試驗裡，最有可能得到的數值第一位，因此又有一個名字：<strong>期望值</strong>。在談論母群或機率模型的場合，通常用希臘字母<span class="math inline">\(\mu\)</span>表示。</p>
<!---
**變異數**與第\@ref(intro)單元提到的柴比雪夫不等式有關，這個不等式指出所有機率模型期望值前後相差k個標準差以外範圍的數值，發生機率總和不超過1/k^2^。如果k等於2，就是總和不超過.25。以n=10，p=0.5的二項分配來說，平均數是5，變異數是2.5，標準差是1.58，所以超過期望值兩個標準差以外的數值有0,1,9,10四個。我們可以運用**累積份佈函數**計算這四個數值的發生機率總和，算法是到數值1的累積機率，加上總機率減去到數值8的累積機率。兩部分的累積機率總和是0.02，確實小於0.25。

再來看n=10，p=0.8的二項分配，有沒有符合柴比雪夫不等式。這個分佈的平均數是8，變異數是1.6，標準差是1.26，所以超過期望值兩個標準差以外的數值有0,1,2,3,4,5六個，計算到數值5的累積機率就能確認。**累積分佈函數**輸出的累積機率是0.03，也是小於0.25。
--->
<p>在討論母群或機率模型的變異數或標準差時，通常使用希臘字母<span class="math inline">\(\sigma^2\)</span>與<span class="math inline">\(\sigma\)</span>表示。傳統統計書會教你查表去找對應數值的累積機率，但是有了jamovi，我們可以搭配程式碼理解如何運用機率，推測正確次數反映的真實能力。</p>
<p><a href="https://osf.io/7ygp4/">jamovi示範存檔</a>展示成功率為0.5與0.8的受測者測試結果之<strong>機率密度函數</strong>，都是根據二項分佈計算的結果。根據二組<strong>機率密度函數</strong>推測可答對至少8次測試的機率，分別是0.05與0.68，因為一般人與有本事的TT答對8次上的機率有如此懸殊的差異，Emily才決定以0.8做為判斷的準則。從一萬次實驗結果的模擬來看，也與計算結果相去不遠。</p>
<p>因此Emily的隨機出題只要符合二項分佈原則，就能根據實驗結果評價受測者的真實能力。不過Emily還需要提出合理的事前預測，才能得到完整的事後機率分配。</p>
</div>
<div id="emily" class="section level3">
<h3><span class="header-section-number">2.1.4</span> 均等分佈：Emily的事前預測</h3>
<p>Emily的實驗目標歸結於一個數值的估計：參與實驗的這群TT隔空感應的成功率究竟有多少？論文提到事前期望十次之中至少有八次正確，也就是說成功率至少有80%或0.8。不過以Emily尚未進行第一次實驗的狀況，最合理的預測是找來的TT成功率從50%到100%都有可能。原因是之前的研究都沒有明確指出當時通過訓練的TT感應成功率是多少，Emily採用最保守的預測，以實驗結果估計的成功率有最高的可能性。要得知這個可能性有多高，必須將預測的成功率放入二項分佈進行模擬。示範如何模擬之前，我們先認識如何用<strong>均等分佈(uniform distribution)</strong>表達Emily第一次實驗之前的預測。</p>
<p>開啟<a href="https://students.brown.edu/seeing-theory/probability-distributions/index.html#section2">機率模型的動畫網頁</a>之前，我們先再次確認成功率是均等分佈的參數，範圍是0.5到1.0。因為均等分佈的數值均為整數，必須轉換才能得知Emily預測得到任何成功率的機率有多高。</p>
<blockquote>
<p>打開<code>uniform distribution</code>預設畫面，你會看到最小值a到最大值b的連續數值的<strong>機率密度函數</strong>，在兩個參數<code>a</code>與<code>b</code>之間，所有數值的發生機率都是相等的。將<code>a</code>改成0，<code>b</code>改成6，兩個參數即可對應成功率50%與100%。<strong>機率密度函數</strong>一致指向0.167，也就是說50%到100%之間任意數值的出現機率，都是0.167。</p>
</blockquote>
<!---
拉動橘色按鈕，你會看到*累積分佈函數*是一個正三角形的斜邊。疊加到了平均數，累積機率剛好到達0.5。這雖然是最能合理解釋gss2010資料分析的假設，但是果真如此，這個世界便沒有什麼值得探討的事物，因為所有結果發生機率都是相同的。

--->
<p>我們當然可以運用模擬，看看各種成功率在10000次實驗結果出現的累積次數。雖然<a href="https://osf.io/7ygp4/">jamovi示範存檔</a>有製造模擬結果的程式碼與輸出直方圖，因為目前jamovi中文顯示的支授還不夠完整，本書重製相同的直方圖於圖<a href="randomization.html#fig:unif-simulation">2.1</a>。這張直方圖分割所有模擬數值到五個區域，所以每一個長方條的頂點都在2000左右。</p>
<div class="figure"><span id="fig:unif-simulation"></span>
<img src="Basic-Statistics-Psychological-Science_files/figure-html/unif-simulation-1.png" alt="Emily Rosa第一次實驗的事前機率分配" width="672" />
<p class="caption">
圖 2.1: Emily Rosa第一次實驗的事前機率分配
</p>
</div>
<p><a href="https://osf.io/7ygp4/">jamovi示範存檔</a>是使用jaomvi的<strong>計算變項(computed variable)</strong>製造模擬數據，讀者可檢視<strong>Aanlyses</strong>視窗<code>TT_before_1st_success_rate</code>欄位，了解欄位裡的每一個細格模擬成功率如何產生。從Emily規劃實驗的狀況來說，這些模擬數據顯示如果她真的做了一萬次實驗，每次實驗測得的成功率。</p>
<p>獲得真實資料後，成功率出現次數的機率將會改變。改變後的機率分配來自結合均等分佈與二項分佈的公式，所產生的模擬數據。之後每個單元介紹的統計方法，都是奠基於某種機率分佈的數學推導，而機率分配的模擬顯示判讀資料的正確方法。</p>
</div>
<div id="section-2.1.5" class="section level3">
<h3><span class="header-section-number">2.1.5</span> 事後機率分配：估計第一次測試的成功率</h3>
<p>將一萬次模擬預測成功率，輸入二項分佈公式，將可以獲得事後機率分配的模擬結果。由於jamovi提供的模擬功能還沒有二項分佈公式，<a href="https://osf.io/7ygp4/">示範存檔</a>的<code>TT_1st_posterior</code>是使用常態分佈公式模擬的數值，其中接近真實平均數(4.667)的數值，才是Emily想知道的測試結果。欄位<code>TT_1st_post_success_rate</code>根據<code>TT_1st_posterior</code>裡符合4與5之間的數值，篩選出<code>TT_before_1st_success_rate</code>的730筆成功率預測值，這些數值就是第一次測試<strong>事後機率分配</strong>。</p>
<p>專業統計論文將事前機率分配的通用數學符號寫成<span class="math inline">\(P(\theta)\)</span>，事後機率分配寫成<span class="math inline">\(P(\theta|D)\)</span>。羅馬字母<span class="math inline">\(\theta\)</span>表示要估計的參數，在這個案例裡就是成功率。大寫字母D就是從實際資料分析得到的資訊，在此就是Emily第一次實驗結算的平均正確率。<a href="https://osf.io/7ygp4/">示範存檔</a>以直方圖呈現事後機率分配的趨勢，如圖<a href="randomization.html#fig:TT-post">2.2</a>所示，次數最多的成功率在0.5到0.6之間，顯然與事前預測的成功率有不少差異。</p>
<div class="figure"><span id="fig:TT-post"></span>
<img src="images/TT-1st-post-success-rate.jpg" alt="Emily Rosa第一次實驗結果的事後機率分配"  />
<p class="caption">
圖 2.2: Emily Rosa第一次實驗結果的事後機率分配
</p>
</div>
<p>至此我們已學到需要統計分析的問題，必須先選定正確的<strong>機率分佈</strong>呈現要估計或預測的參數。參數是我們運用收集到的資料，評估測量目標出現次數，進而推測事前估計或預測為真的可能性。統計實務裡，評估出現次數的工作是<strong>描述統計</strong>、推測可能性的工作是<strong>推論統計</strong>。深入探討Emily的研究細節，你應該對兩種工作有更進一步的體會：統計實務要取得有助結論的<strong>事後機率分配</strong>。有這樣的認識，就能理解任何需要統計分析的領域，必須先認識共同的基礎項目。<strong>事後機率</strong>是一種<strong>條件機率</strong>，我們要先知道一些基本的運算定理。</p>
</div>
</div>
<div id="section-2.2" class="section level2">
<h2><span class="header-section-number">2.2</span> 條件機率的計算與模擬</h2>
<p>在此暫時放下Emily Rosa的案子，談一談二十世紀下半葉，美國統計學界提出的著名公案：蒙提霍爾問題<span class="citation">(Steve, <a href="#ref-Steveproblemprobabilityletter1975">1975</a>)</span>。蒙提霍爾是二十世紀六十年代著名的美國猜謎節目主持人，這個節目有個知名橋段：主持人向觀眾展示三道門，其中一道門之後是豪華轎車，另外兩道門之後是山羊。每集節目邀請來賓選出正確的門，選到車子現場直接開回家。不過這個橋段有個製造緊張氣氛的安排：來賓先指出其中一道門，接著主持人打開另外兩道門的其中一道，這道門之後一定是山羊。最後就是橋段的高潮，主持人給來賓一次機會，選擇一開始指出的門？還是選沒擇被打開的另一道門？</p>
<p>統計學者與數學家最關心的是這個節目的來賓，選擇另一道門是車子的機率有沒有高於一開始選擇的門？這種情況就是<strong>條件機率</strong>的比較：已知其中一道門之後是山羊(B)，一開始指的門是車子(A)之機率。為了方便計算，一般寫成<span class="math inline">\(P(A|B)\)</span>。同樣的道理，<span class="math inline">\(P(\bar{A}|B)\)</span>代表已知其中一道門之後是山羊(B)，另一道門是車子(<span class="math inline">\(\bar{A}\)</span>)之機率。雖然<span class="math inline">\(P(A|B)\)</span>與<span class="math inline">\(P(\bar{A}|B)\)</span>的總和是1，但是B也是一種機率事件，因為到底那道門之後是山羊，每一集節目都不會一樣。下表列出所有車子與山羊的情況：</p>
<table>
<thead>
<tr class="header">
<th align="center">狀況</th>
<th align="center">1號門</th>
<th align="center">2號門</th>
<th align="center">3號門</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">車</td>
<td align="center">羊</td>
<td align="center">羊</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">羊</td>
<td align="center">車</td>
<td align="center">羊</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">羊</td>
<td align="center">羊</td>
<td align="center">車</td>
</tr>
</tbody>
</table>
<p>節目主持人先讓來賓指出一道門，接著根據情況決定要打開那道門讓觀眾與來賓看山羊。例如車子在1號門之後的狀況，來賓先選擇1號門，接著主持人就隨機打開2號門或3號門；如果是車子不在1號門之後的狀況，來賓先選擇1號門，主持人接著就打開另一道是山羊的門。所以主持人要打開那道門讓觀眾看山羊，也是一種隨機事件。不過主持人打開那道門的機率，與來賓最後選那一道門中車子的機率無關。</p>
<p>讀者可以找到許多說明來賓最後該選那一道門的機率計算方法，不過我們都學過模擬機率的方法，將蒙提霍爾問題的來賓面對選擇的條件，轉化成R程式碼，就能得知上千次來賓都決定選擇另一道門，會中車子的機率。圖<a href="randomization.html#fig:Monty">2.3</a>來自<a href="https://osf.io/vm63s/">蒙提霍爾問題jamovi範例</a>，模擬一萬次來賓決定換門而贏得車子的次數與沒有贏得車子的次數。</p>
<div class="figure"><span id="fig:Monty"></span>
<img src="images/Monty-Hall.png" alt="蒙提霍爾問題一萬次模擬的事後機率分配"  />
<p class="caption">
圖 2.3: 蒙提霍爾問題一萬次模擬的事後機率分配
</p>
</div>
<p>由模擬結果可知，換門而贏車的次數比換門而未贏車的次數高出一倍，也就是說<span class="math inline">\(P(A|B)\)</span>約1/3，<span class="math inline">\(P(\bar{A}|B)\)</span>約2/3。如果使用機率原理計算，也會得到相同的結果。讀者也許看過其他計算的解說方法，在此我們要使用貝氏定理解說來賓換門贏車的條件機率的計算方法。</p>
<div id="section-2.2.1" class="section level3">
<h3><span class="header-section-number">2.2.1</span> 從蒙提霍爾問題理解貝氏定理</h3>
<p>讀者也許曾經學過貝氏定理的公式，本書談到貝氏定理的地方都是使用以下公式：</p>
<p><span class="math display">\[ P(\theta|D) = \frac{P(D|\theta) \times P(\theta)}{P(D)} \]</span></p>
<p>D表示資料，就像Emily Rosa的實驗結果；<span class="math inline">\(\theta\)</span>表示要估計的參數，或者理論的預測值，就像TT的感應成功率。</p>
<p>以蒙提霍爾問題的情境來說，D代表主持人打開有山羊的門，<span class="math inline">\(\theta\)</span>代表來賓換門贏車。我們表列來賓先選1號門，後來決定不選另一個門的各種結果，來說明如何利用貝氏定理計算<strong>不換門而贏車</strong>的事後機率。</p>
<table>
<thead>
<tr class="header">
<th align="center">狀況</th>
<th align="center">1號門</th>
<th align="center">2號門</th>
<th align="center">3號門</th>
<th align="center">結果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">車</td>
<td align="center">羊</td>
<td align="center">羊</td>
<td align="center">得車</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">羊</td>
<td align="center">車</td>
<td align="center">羊</td>
<td align="center">得羊</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">羊</td>
<td align="center">羊</td>
<td align="center">車</td>
<td align="center">得羊</td>
</tr>
</tbody>
</table>
<p>如果來賓是研究者，<span class="math inline">\(P(\theta)\)</span>就是來賓一開始的理論預測成功的機率，上列表格得知三種狀況之中只有一種符合，所以<span class="math inline">\(P(\theta)\)</span>是1/3。而且不論來賓一開始選擇那道門，<span class="math inline">\(P(\theta)\)</span>都是1/3。</p>
<p>主持人打開後面是羊的門，就像研究者有了預測之後，根據理論收集的資料。來賓預期如果一開始選的門是對的，其餘兩個門會被主持人打開的機率應該是相等的。因此只以狀況A來說，主持人打開2號門或3號門的機率是一樣的，所以<span class="math inline">\(P(D)\)</span>是1/2。因為是以來賓一開始的選擇決定狀況，所以任何狀況主持人會開那一道門的機率都是1/2。</p>
<p>在這場節目的狀況，<span class="math inline">\(P(D|\theta)\)</span>代表來賓應該考慮不論自己的猜測是否正確，主持人向觀眾開啟這道門的機率。如果一開始猜車子在1號門，主持人打開2號門可能是其中兩種狀況：第一種是狀況A，主持人可以打開2號門或3號門；第二種是狀況C，主持人能打開的只有2號門。不必考慮狀況B是因為車子在2號門之後，主持人不可能開門。所以如果一開始選擇1號門，接著主持人會打開2號門的狀況機率是相等的，也就是1/2。同樣的道理，主持人打開3號門的條件機率也是1/2。相同地，不論來賓一開始選那道門，來賓應考慮其餘的門被主持人打開的條件機率，一律是1/2。</p>
<p>在許多研究的狀況，<span class="math inline">\(P(D|\theta)\)</span>是根據理論的預測，能發現目前資料的條件機率。這是本書各單元範例與習題，所展示的資料之抽樣來源，本質是某種<span class="math inline">\(P(D|\theta)\)</span>的機率分配。心理學者廣泛使用統計方法之後，大部分學習內容奠基於這類條件機率。</p>
<p>以上三種機率代入貝氏定理的公式，就能得到來賓決定一開始選的門，能得到車子的機率是1/3。計算與模擬雖然得到相同答案，但是過程不相同，主要差異在於模擬不必考慮主持人的行動，只考慮來賓的最後選擇，也就是上述三種機率的總成。這也是為何<a href="https://osf.io/vm63s/">jamovi範例</a>的程式碼，只有模擬<strong>來賓的選擇</strong>與<strong>真正有車的門</strong>：</p>
<pre><code># door number: 1,2,3
# Player&#39;s decision 
playerChoice &lt;- sample(1:3,1)
# Where is the car
prizeDoor &lt;- sample(1:3,1)</code></pre>
<p>使用貝氏定理解說蒙提霍爾問題，我們可以發現來賓的猜測與最後不換門會得到車子機率都是1/3。如果這個節目都是採用這樣的遊戲流程，決定換門的來賓們大約每三位會有兩位會開車回家。以貝氏定理算出的事後機率，可做為下次研究的事前機率，很顯然參與蒙提霍爾節目的來賓，並不能靠過去的播出紀錄更新中獎機率。</p>
<blockquote>
<p><strong>註：</strong>蒙提霍爾問題的計算說明，改編自余海峯博士的直播錄影存檔：<a href="https://youtu.be/176RDyzlJck" class="uri">https://youtu.be/176RDyzlJck</a></p>
</blockquote>
</div>
<div id="tt" class="section level3">
<h3><span class="header-section-number">2.2.2</span> 使用事後機率推測TT的能力</h3>
<p>科學研究的重要任務是以發現的結果更新事前的猜測，所以事後機率分配不同於事前預期的研究結果，才是真正有意義的科學研究。我們順此再談Emily Rosa測試TT感應成功率的研究，了解Emily第一次實驗結果如何更新她對TT能力的想法。</p>
<p>圖<a href="randomization.html#fig:TT-post">2.2</a>呈現的事後機率分配，是來自Emily研究<a href="https://osf.io/7ygp4/">jamovi示範存檔</a>的欄位<code>TT_1st_post_success_rate</code>，這個欄位正是以貝氏思維–或者說由貝氏定理發展出來的思考方法–產生的模擬資料，對應貝氏定理公式的<span class="math inline">\(P(\theta|D)\)</span>。存檔裡的另外兩個計算變項欄位<code>TT_before_1st_success_rate</code>與<code>TT_1st_posterior</code>，分別對應貝氏定理公式的<span class="math inline">\(P(\theta)\)</span>與<span class="math inline">\(P(D|\theta)\)</span>。至此你應該要問，怎麼沒有<span class="math inline">\(P(D)\)</span>的機率分配？因為實際的研究收集到任何次數的資料可能性是一致的，在統計實務通常設定<span class="math inline">\(P(D)\)</span>為1。實務如同<a href="https://osf.io/7ygp4/">示範存檔</a>的設定，從<span class="math inline">\(P(D|\theta)\)</span>的機率分配選出匹配資料的數據，形成<span class="math inline">\(P(\theta|D)\)</span>的事後條件機率分配。<span class="math inline">\(P(\theta|D)\)</span>代表Emily完成第一次實驗之後，對於TT們真實能力的最新想法。</p>
<p><span class="math inline">\(P(\theta|D)\)</span>機率分配有700筆數據，其中成功率大於80%的數據有5筆，所以Emily能從這群TT找到符合預期之人的機率大約是0.01。因為<span class="math inline">\(P(\theta|D)\)</span>是<span class="math inline">\(P(D|\theta)\)</span>的一部分，我們以符合預期成功率與資料平均數兩個條件，區分<span class="math inline">\(P(D|\theta)\)</span>模擬數據到如下表的四個種類。之後的單元，我們還會利用這張表理解假設檢定的運用原理：</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">不符合預期( &lt; 80% )</th>
<th align="center">符合預期( &gt; 80% )</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">成功次數為4或5次</td>
<td align="center">695</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td align="center">成功次數非4或5次</td>
<td align="center">4246</td>
<td align="center">3954</td>
</tr>
</tbody>
</table>
<p>Emily在幾個月之後又找了13位TT再做一次研究。如何使用相同的方法分析第二次研究的資料，做出更新的結論？這就做為習題讓讀者自我學習，本章於總結統計學兩大流派後告一段落。</p>
</div>
</div>
<div id="section-2.3" class="section level2">
<h2><span class="header-section-number">2.3</span> 統計學兩大流派</h2>
<p>Emily Rosa研究結果的<a href="https://osf.io/7ygp4/">jamovi示範存檔</a>報表最後部分呈現第一次研究結果的平均值與標準差等資訊，這些資訊是使用jamovi的描述統計模組<code>Exploration</code>，分析<code>Emily_1st</code>欄位的結果，也是原始論文表格呈現的資訊。這份報表是示範裡唯一呈現描述統計的部分，而平均數資訊提供事後機率分配<code>TT_1st_post_success_rate</code>的數據挑選範圍。由此我們可以分辨描述統計(descriptive statistics)與推論統計(inference statistics)的功能：描述統計集合各種呈現資料中“可推論資訊”的技巧，以適當的測量尺度呈現資料的<strong>集中</strong>與<strong>變異</strong>。推論統計評估“可推論資訊”符合預測的可能性，或者值得再做探討的價值。</p>
<p>現代統計學的發展歷史與心理學等需要分析資料的科學領域相輔相成。首先被廣泛使用的推論統計方法需要的計算資源較少，這個單元示範的機率分配模擬，直到十幾年前才開始在個人電腦實現，所以需要較多計算資源的統計方法能被更多人使用。Emily Rosa研究結果的示範分析是一種<strong>貝氏統計(Bayesian Statistics)</strong>的展示，而本書各單元主要介紹的是<strong>次數主義統計(Frequenitist Statistics)</strong>。</p>
<div id="section-2.3.1" class="section level3">
<h3><span class="header-section-number">2.3.1</span> 次數主義統計</h3>
<p>這個單元的<a href="https://osf.io/7ygp4/">TT感應研究示範存檔</a>與<a href="https://osf.io/vm63s/">蒙提霍爾問題示範存檔</a>都有模擬機率分配的部分，模擬方式都是累積一萬次實驗結果，以多次實驗累積的機率分配推論資訊，正是次數主義的中心思想。所有研究問題都有一個最適合的機率分佈，只要能用最接近的機率分配評估資料出現的機率，就能用最適合的統計方法。</p>
<p>許多研究問題的機率分配是總計根據某種假設，當前資料的發生次數，也就是前面討論貝氏定理時提到的<span class="math inline">\(P(D|\theta)\)</span>。許多次數主義統計方法原理是建立在這種條件機率分配，但是研究者不必製造模擬數據，只要確定收集資料的條件符合要素，<span class="math inline">\(P(D|\theta)\)</span>必定接近預設的機率分佈，通常是<strong>常態分佈(Normal Distribution)</strong>。常見的要素有常態性(Normality)與等變異性(Equal variance)，統計學家也開發許多方法，幫助研究者確認手上的資料符合這些要素，讓研究者能合理運用統計方法得到的資訊推論。</p>
<p>然而包括心理學在內的多數社會科學研究者，在學習次數主義統計方法的過程中並未充分理解<span class="math inline">\(P(D|\theta)\)</span>不等於真正想研究的<span class="math inline">\(P(\theta)\)</span>，近幾年更導致全面更改使用統計方法慣例的議論四起<span class="citation">(Benjamin et al., <a href="#ref-benjamin_redefine_2017-1">2017</a>, <span class="citation">Lakens et al. (<a href="#ref-LakensJustifyyouralpha2018">2018</a>)</span>)</span>。次數主義統計方法雖然是本書的學習重點，我會在每個範例提示使用建議。</p>
</div>
<div id="section-2.3.2" class="section level3">
<h3><span class="header-section-number">2.3.2</span> 貝氏統計</h3>
<p>貝氏統計不必設定<span class="math inline">\(P(D|\theta)\)</span>符合那一種機率分佈，而是設定<span class="math inline">\(P(\theta)\)</span>符合的機率分佈，運用現有資料及模擬程序製造<span class="math inline">\(P(D|\theta)\)</span>的機率分配，以此得出的<span class="math inline">\(P(\theta|D)\)</span>機率分配用於推測資料意義或投入下一輪資料分析。因為真實的心理學研究課題包含許多變項，模擬程序需要複雜的演算法與計算資源，目前最常被應用的演算法是馬可夫蒙地卡羅方法(Markov chain Monte Carlo,簡稱MCMC)。</p>
<p>兩大流派的共同點是<strong>能用統計方法處理的資料必須是透過隨機程序所得</strong>，像是調查使用的抽樣，還有實驗的分派，<span class="math inline">\(P(D|\theta)\)</span>才能符合方法原理的設定或可用演算法進行數據模擬。由於兩大流派的差異是處理<span class="math inline">\(P(D|\theta)\)</span>的方式，所以每種已經發展成熟的次數主義統計方法都有對應的貝氏統計方法。本書設定讀者是統計初學者，不會直接介紹貝氏統計方法，每個介紹統計方法的單元最後，都會簡介貝氏統計方法的學習資源。</p>
<!---
打開預設畫面你看到的常態分佈**機率密度函數**，設定參數是平均數$\mu = 0$，標準差$\sigma = 1$。常態分佈的特性是只要參數確定，不管你得到的數值是什麼，發生機率與累積都是固定的。如果要分析gss2010的**科學知識評分**，我們可以假設美國人的表現平均數是5，標準差是2(實際資料平均數是5.95，標準差是2.37，不過我們現在討論的是母群，而非樣本)。你會發現這個常態分佈除了最小值0與最大值10，所有數值的發生機率都朝平均數遞增。如果你改變標準差，最明顯的變化是平均數的發生機率與標準差大小成反比，請記得這個特點，稍後解剖抽樣分佈會是關鍵。

拉動橘色按鈕，你會看到**累積分佈函數**是一條曲線，在平均數處出現轉折。改變平均數不影響曲線的樣貌，但是改變標準差會跟著機率密度函數的範圍伸縮。這個特性讓我們可以不管標準差多大，計算固定標準差範圍內數值的累積機率，都會是相等的。

統計實務我們希望資料的分配是常態分佈，因為以上的特點讓每個數值的發生機率能夠明確估計。然而常態分佈是可遇不可求，我們得到的資料都是不完全符合，如果需要使用常態分佈處理資料，統計學家已經開發出很多種轉換方法，這個單元結束之前，我會示範一種方法。

## 打造抽樣分佈的隱形之手：中央極限定理

這個小單元我使用jamovi製造幾份虛擬資料，請你跟著演練，觀察各種統計結果之間的規律。接著再來解剖[seeing theory的中央極限定理動畫](https://students.brown.edu/seeing-theory/probability-distributions/index.html#section3)，你會發現每次分析手上的資料，只是眾多樣本的其中一個。

示範之前認識jamovi的另一種欄位型態：計算變項(Computed Variable)。jamovi的`Data`選單裡有可新增與刪除變項的功能，新增變項可選擇增加資料變項或計算變項。確定增加計算變項，會出現公式編輯選單。如果你有使用Excel函數的經驗，計算變項選單的操作大同小異。Jonathon Love有製作動畫示範圖，展示新增計算變項的流程，請參考他的[部落格](https://blog.jamovi.org/2017/11/28/jamovi-formulas.html)。

### 均等分佈的樣本分析

請先下載[示範檔案](https://osf.io/bwapf/)，這個檔案已經有15個以最小值0及最大值10的均等分佈，產生90筆隨機數值的計算欄位。還有兩個計算欄位是計算前五欄的平均，以及前十欄的平均。示範檔案已經分析最後兩個計算欄位的平均數、變異數與標準差。請記得這個均等分佈的平均數是5，變異數是8.3333333，你可以觀察看看jamovi的描述統計結果，兩個欄位的平均數是不是很接近5？五欄平均的變異數是不是大於十欄平均的變異數，而且兩者都小於均等分佈的變異數？

你可以再製造一個十五欄平均的`計算變項`，做一次描述統計會發現平均數同樣接近5，但是變異數更小了。請你將均等分佈的變異數8.3333333，分別除於5,10,15，應該會發現很接近jamovi算出來的變異數，而且十五欄平均的變異數會是最接近的。你可以增加更多計算欄位，像是`UNIF016`、`UNIF017`，增加到20項、25項等等，觀察看看二十欄平均的平均數與變異數與前者的差異？**建議在此做個筆記，等一下是剖析中央極限定理的關鍵。**

### 常態分佈的樣本分析

請先下載[示範檔案](https://osf.io/6bqme/)，這個檔案已經有15個以平均數5及變異數4的常態分佈，產生90筆隨機數值的計算欄位。還有兩個計算欄位是計算前五欄的平均，以及前十欄的平均。示範檔案已經分析最後兩個計算欄位的平均數、變異數與標準差。請記得這個常態分佈的平均數是5，變異數是4，你可以觀察看看jamovi的描述統計結果，兩個欄位的平均數是不是很接近5？五欄平均的變異數是不是大於十欄平均的變異數，而且兩者都接近常態分佈的變異數1/5及1/10倍？

你可以再製造一個十五欄平均的計算變項，做一次描述統計會發現平均數同樣接近5，變異數更小了。同樣地，也可以增加計算變項，看看更多樣本的描述統計與前者的差異。**你有沒有注意到，雖然母群是常態分佈，樣本分析結果與均等分佈的本有一致的規律。**

### 剖析中央極限定理

<iframe 
    src="https://students.brown.edu/seeing-theory/probability-distributions/index.html#section3" 
    width="100%" 
    height="750px" 
    scrolling="no"
    style="margin-top: 15px;margin-bottom: 15px;"
    frameborder="1">
</iframe>

注意到這個規律之後，我們可以來剖析[中央極限定理動畫](https://students.brown.edu/seeing-theory/probability-distributions/index.html#section3)。這個範例的母群是**貝他分佈(Beta distribution)**，有兩個可以自訂的參數$\alpha$與$\beta$。預設的兩個參數都是1，如此設定的貝他分佈相同於最小值是0且最大值是1的均等分佈。如果兩個參數都是5，這個貝他分佈就相等於平均數是0.5，變異數是0.023的常態分佈。我們用這兩種設定，觀察接下來的抽樣分佈。

建議先在左方頁面的`Sample size`與`Draw`填入任意數值，然後勾選`Theoretical`，右方頁面會立刻顯示抽樣分配的**機率密度函數**。你可以先任意調整貝他分佈的參數，會發現不論母群如何變化，抽樣分配都是常態分佈，只是平均數與變異數會有些微差異。這是數學家發現中央極限定理的第一件事：**不論你預期的母群機率模型是什麼，抽樣分配都是常態分佈**。

左方頁面下方兩個可填入的空格`Sample size`與`Draw`，相同於jamovi示範裡的計算變項欄位，以及每個欄位的觀察值。示範網頁的`sample size`可填入的最大數值是15，`Draw`可填入的最大數值是100。建議先在`Draw`填入90，`sample size`依序填入5、10、15，你會發現抽樣分配的**機率密度函數**會有變異數或標準差的變化。這是數學家發現中央極限定理的第二件事：**抽樣分配的變異數，是母群變異數除以樣本數(sample size)**。

設定好`sample size`與`Draw`，你可以按submit，網頁會跑出模擬數據抽樣平均數的直方圖。這個過程就像jamovi示範製造五欄及十欄平均等計算變項，再做描述統計。請改變`sample size`多跑幾次，你會發現`sample size`越大，直方圖越接近抽樣分配的**機率密度函數**。這個現象與中央極限定理的數學原理關係不大，但是是統計實務要牢記的訊息：試驗的樣本數越大，抽樣分配越逼近母群的平均數與變異數。

## 條件機率與抽樣

至此我們需要好好想想一個問題：抽樣分配與母群是不同的機率模型，就算母群是常態分佈，平均數與變異數也不大相同。那麼用抽樣分配估算資料數值的發生機率或累積機率，真正的意思是什麼？

要理解這個問題，需要重新學習你可能曾經聽過的**條件機率(conditional probability)**，我們用[seeing theory的條件機率動畫](https://students.brown.edu/seeing-theory/compound-probability/index.html#section3)搭配解說。這個動畫有三層板子(A,B,C)由上而下排列，不斷有球從上落下。由於這個單元一開始，我們就已經解析模擬蜜蜂回巢的隨機變數動畫，你可以把這三層板子想成一座蜂巢的一部分，每隻回巢的蜜蜂要到巢內的目的地，可能只要穿越A層或C層，可能要穿越A與B，或者B與C。在左方頁面下方的長條度，你會看到所有蜜蜂穿過每一層的機率都是相等的(0.33)，全部機率加起來是1。

<iframe 
    src="https://students.brown.edu/seeing-theory/compound-probability/index.html#section3" 
    width="100%" 
    height="750px" 
    scrolling="no"
    style="margin-top: 15px;margin-bottom: 15px;"
    frameborder="1">
</iframe>

按一下按鈕A，右方頁面會縮放到整個A層，包括在下面的一半B層。此時右方頁面是紀錄通過A之後，有到達B層或沒有到達B層的蜜蜂個數。所以左方長條圖橫軸變成三個數值$P(A|A),P(B|A),P(C|A)$，表示先通過A，再通過A,B,C的**條件機率**。因此$P(A|A)$的發生機率自然是1，通過A層的有一半會到達B層，所以P(B|A)是0.5，最後C層不在畫面裡，沒有通過A層的會到達C層，機率當然是0。

抽樣分配的形成過程就像紀錄通過A層並到達B層的蜜蜂數量，所以抽樣分配呈現的機率是一種條件機率：我們先透過隨機程序安排受測對像(A)，再使用可實作的測量方法收集資料(B)，以此估計預期事件的發生機率。如此一來資料有沒有分析的價值有兩個重點：首先是你的研究過程有沒有充分執行隨機程序？再來是收集到的資料有沒有符合常態分佈？

你採取的研究方法決定第一個重點的成敗，但不是這本書的重點。至於第二個重點，我們在解析中央極限定理已經學到足夠的樣本數是關鍵，但是不是每筆資料都能完美符合，如何檢查樣本資料符合常態分佈的程度？如果可一做適當的校正，讓資料符合常態分佈，該怎麼做？是本單元最後的學習重點。

## 資料密度的視覺化與轉換

要知道樣本資料接近常態分佈的程度，最簡單的方法是看集中趨勢的三種統計量數是否相同。常態分佈的平均數、中位數與眾數是相同的。如果不同，要評估不符合常態分佈的程度，傳統的方法是計算偏態(skewness)與峰度(kurtosis)，現在可以繪製**箱形圖(boxplot)**與**小提琴圖(violine plot)**，評估偏離常態分佈的程度。JASP與jamovi的描述統計模組都有繪製兩種圖的功能。

在此使用gss2010**科學知識評分**資料示範，示範檔案可從[連結A](https://osf.io/vy2fd/)與[連結B](https://osf.io/8f9bu/)下載。圖\@ref(fig:box-violin-demo)是JASP與jamovi將箱形圖與小提琴圖重疊輸出的結果，中間的箱形圖是以25%百分位數、中位數與75%百分位數構成中央的長方形與中間粗線。如果資料越不符合常態分佈，三個數值差距會越大。小提琴圖是最逼近資料的**機率密度函數**，到這裡我們已經看過不少seeing theory的動畫示範，你對常態分佈的**機率密度函數**應該有有深刻印象，肉眼就能判斷偏離常態分配的程度。


<div class="figure" style="text-align: center">
<img src="images/gss2010-sciknow-plots.jpg" alt="gss2010科學知識評分的箱形圖與小提琴圖。左圖用JASP輸出，右圖用jamovi輸出。" width="90%" />
<p class="caption">(\#fig:box-violin-demo)gss2010科學知識評分的箱形圖與小提琴圖。左圖用JASP輸出，右圖用jamovi輸出。</p>
</div>

JASP與jamovi的繪圖選項都在統計模組的Plots選單裡。JAPS要先勾選`Display boxplots`，然後勾選`Boxplot Element`與`Violin Element`，就會輸出圖\@ref(fig:box-violin-demo)的結果。如果你想辨識實際的資料密度，乃至極端值，可勾選`Jitter Element`與`Label Outliers`。jamovi直接勾選`Box plot`與`Violine`兩個選項，就能輸出圖(待編輯)。這兩種的視覺呈現何種較佳見仁見智，但是都顯示整筆資料偏向大於5的評分。

如果你想要讓**科學知識評分**資料更符合常態分佈，你可以使用**z分數轉換**。現在能直接在軟體裡做到的只有jamovi，所以請見(Link B)的檔案內容示範。方法是創建一個計算變項，把每個科學知識評分的原始分數減去平均數，再除以標準差，你可以檢視計算變項`ScientificKnowledge_Z`的設定，接著在公式欄位裡輸入以下資訊：

```
(ScientificKnowledge - VMEAN(ScientificKnowledge))/VSTDEV(ScientificKnowledge)
```

統計實務需要進行**z分數轉換**的時機，是你不想或不能排除資料裡的極端值，又需要讓資料符合常態分佈，分析結果才能做有效推論。在調查研究常有轉換整筆資料的機會，不過在檢定假設的場合，剔除或轉換極端值可以讓資料更符合常態分佈的話，就不會轉換整筆資料。

--->
</div>
</div>
<div id="-1" class="section level2">
<h2><span class="header-section-number">2.4</span> 習題</h2>
<p>Emily Rosa完成第一次研究之後，應採訪記者的請求，找了包括曾參與第一次研究的7位TT等13名受測者。這13位各自接受十次測試的正確次數是1,3,3,3,3,4,4,4,4,5,5,7,7。請以第一次研究之後更新的事後機率分配做為第二次的事前預測，製作第二次研究的事後機率分配模擬數據，以此判斷Emily Rosa能找到的TT有至少80%成功率的可能性。</p>

</div>
</div>
<h3>參考文獻</h3>
<div id="refs" class="references">
<div id="ref-Steveproblemprobabilityletter1975">
<p>Steve, S. (1975). A problem in probability (letter to the editor). <em>American Statistician</em>, <em>29</em>(1), 67.</p>
</div>
<div id="ref-benjamin_redefine_2017-1">
<p>Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … Johnson, V. E. (2017). Redefine statistical significance. <em>Nature Human Behaviour</em>, 1. doi:<a href="https://doi.org/10.1038/s41562-017-0189-z">10.1038/s41562-017-0189-z</a></p>
</div>
<div id="ref-LakensJustifyyouralpha2018">
<p>Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., … Zwaan, R. A. (2018). Justify your alpha. <em>Nature Human Behaviour</em>, <em>2</em>(3), 168–171. doi:<a href="https://doi.org/10.1038/s41562-018-0311-x">10.1038/s41562-018-0311-x</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="one-sample.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"fontfamily": "Microsoft JhengHei"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
