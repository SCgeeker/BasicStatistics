[
["randomization.html", "第2單元 機率與隨機方法 2.1 從案例學習機率的計算與模擬 2.2 條件機率的計算與模擬 2.3 統計學兩大流派 2.4 習題", " 第2單元 機率與隨機方法 第1單元的最後，我們示範分析2010年美國一般社會調查的部分資料(T. W. Smith, Marsden, Hout, &amp; Kim, n.d.)。這種資料是用隨機方法從母群抽取樣本的分析結果，讓我們能用統計方法分析其中資訊，並以此以宣稱調查結果顯示2010年美國社會的狀況。研究者能在報告寫出可靠的結論，是根據數學家發現的機率模型與統計學家創造的應用方法，讓我們能轉化問題為統計思考的命題，分析資料檢驗結論的可靠性。 第1單元也提到Emily Rosa驗證治療性撫慰師能力的研究，這個單元我們將從這個研究案，學習如何運用機率與隨機方法，根據測試資料推測參與研究的治療性撫慰師們，隔空感應人體能量場的真實能力。我們會學習到什麼是計算的機率與模擬的機率；在Emily的案例裡，我們將了解為何均勻分佈能估計撫慰師們的能力？為何二項分佈能呈現判斷撫慰師真實能力的標準？為何隨機方法能結合均勻分佈與二項分佈？ 為了讓學生了解計算的機率與模擬的機率在統計分析實務展現的功能，這個單元的操作示範都是使用jamovi。因為模擬機率分配需要使用R程式碼，請讀者開啟這個單元提供的示範檔案之前，確認個人使用的jamovi版本是0.9以上，並且已經安裝Rj(Editor to run R code inside jamovi)模組。 2.1 從案例學習機率的計算與模擬 首先請讀者區別兩個名詞：機率分佈與機率分配，對應的英文詞都是probability distribution，兩種中文名詞亦在各種書籍與論文使用。本書使用機率分佈的狀況是在說明如何計算有限事件的出現機率，是以法則計算或用數學公式推導，能直接用紙筆計算，也可以用R程式碼表現；機率分配是根據機率模型模擬預期事件的出現次數，必須使用程式碼操作計算機，產生模擬結果。 2.1.1 機率模型動畫頁面說明 機率模型的動畫網頁展示本書會提到的各種機率分佈，網頁能顯示特定範圍內的機率事件，使用者可對照網頁備註中的公式，從顯示為黃色線條及陰影的機率密度函數(probability density function)，了解如何計算對應事件的機率。也能由橘色展示的累積分佈函數(Cumulative distribution function)，得知一定範圍內事牛的累積發生機率。之後需要讀者仔細檢視機率分佈的地方，會有提示依照描述的條件，親自操作動畫網頁。 為了讓讀者親手探索Emily的研究過程，請先下載jamovi示範存檔。這個存檔必須以jamovi 0.9以上版本才能開啟，並請讀者先確認自己的jamovi已經安裝Rj套件。 2.1.2 伯努力分佈：一位TT進行一次測試的成功率 假想Emily Rosa還未想出她的實驗方法之前，任何一位TT要宣傳自己的能力，或者任何一位民眾想證實某位TT的能力，最直接的證實方法是看這位TT執行治療的成功率，有沒有達到宣稱的水準。如果TT的能量場理論是正確的，沒有受過訓練的一般人成功率大約是50%，受過訓練的TT有80%以上的成功率。這些狀況能使用伯努力分佈展示，我們先使用機率模型的動畫網頁的Bernoulli random variable，看看TT與一般人感應能量場成功率的差異。 打開預設畫面你看到的只有0與1兩個數值，我們設定1代表感應成功，0代表感應失敗。參數p決定1的出現機率，也就是成功率；而0的出現機率就是失敗率，剛好是\\(1-p\\)。調整左側視窗最下面的p，可以改變伯努力分佈的機率密度函數。p調整為0.5就是一般人感應能量場的成功率，0.8就是受過訓練的TT應該有的成功率。拉動橘色按鈕，還可以看到累積分佈函數是0與1機率的逐步疊加。因為只有兩個數值，所以只有從0到1兩步疊加就到頂點。 Emily研究的jamovi示範存檔有一段R程式碼，呈現成功率是10%到100%十種人士的伯努力分佈。實際測試則需要累積多次紀錄，比如說一萬次，計算實際的成功率。要了解實際成功率與計算得知的機率相差多少，除了做一次真正的實驗，就是運用模擬，看看機率分配與伯努力分佈的差異。jamovi示範有一行R程式碼，使用p為0.8的伯努力分佈模擬一萬次測試，得到的成功率。每次執行結果都會不一樣，不過都與0.8相差不大。請執行伯努力分佈與分配的程式碼幾次，了解機率計算與模擬的不同。 然而真的找來找一位TT，按照Emily設計的測試方法做一萬次，其實想一想有許多不可行之處。第一點，找一個人來做一萬次這樣的測試不知道要做多久？再者受測者與施測者不可能不間斷地做一萬次測試，否則測試結果必定有偏誤。所以Emily想出的設計並非根據伯努力分佈，不過伯努力分佈是很簡單的機率分佈，模擬的機率分配也很容易用任何你會操作方法重現。 2.1.3 二項分佈：n位TT進行x次測試的成功率 Emily的論文記載的方法是找來十幾位TT，請每位做十次測試。由於每次測試都是擲硬幣決定要測試的手，所以這場實驗的隨機程序與可能的結果，都可以用二項分佈計算。我們先使用機率模型的動畫網頁的binomial random variable，了解一般人與TT的表現差異。 打開預設畫面你看到6個數值：0,1,2,3,4,5，這是由參數n設定，這個數值表示一次實驗的測試次數，只要調整為10，就符合Emily的TT測試設定。參數p是受測者的成功率，預設的0.5代表一般人，把座標圖縮放到適當尺寸，就會看到答對5次的機率最高。如果一位TT有0.8的成功率，將參數p改為0.8，就會看到答對8次的機率最高。請留意，無論是那一種測試者，二項分佈的機率密度函數計算的最大機率都不到0.3，因為這個機率值是多次實驗最可能的結果，有最大機率的參數n稱為期望值。 拉動橘色按鈕，你會看到累積分佈函數從數值1開始疊加到最後一個數值。疊加的幅度與數值的出現機率成正比，所以你會看到數值5之前的幅度較大。如果你改變參數p，像是認為TT真有本事，p應該到少等於0.8。調整完你會看到除了數值8的出現機率最高，累積分佈函數的疊加幅度也是到數值8為最高。 在這裡我們可以理解左方頁面的平均數與變異數的意義。請先重新調整二項分佈的參數：n等於10，p等於.5，你會注意到這個設定的平均數是5，也就是兩個參數的乘積，累積機率也是0.5。所以平均數是這個設定的試驗裡，最有可能得到的數值第一位，因此又有一個名字：期望值。在談論母群或機率模型的場合，通常用希臘字母\\(\\mu\\)表示。 在討論母群或機率模型的變異數或標準差時，通常使用希臘字母\\(\\sigma^2\\)與\\(\\sigma\\)表示。傳統統計書會教你查表去找對應數值的累積機率，但是有了jamovi，我們可以搭配程式碼理解如何運用機率，推測正確次數反映的真實能力。 jamovi示範存檔展示成功率為0.5與0.8的受測者測試結果之機率密度函數，都是根據二項分佈計算的結果。根據二組機率密度函數推測可答對至少8次測試的機率，分別是0.05與0.68，因為一般人與有本事的TT答對8次上的機率有如此懸殊的差異，Emily才決定以0.8做為判斷的準則。從一萬次實驗結果的模擬來看，也與計算結果相去不遠。 因此Emily的隨機出題只要符合二項分佈原則，就能根據實驗結果評價受測者的真實能力。不過Emily還需要提出合理的事前預測，才能得到完整的事後機率分配。 2.1.4 均等分佈：Emily的事前預測 Emily的實驗目標歸結於一個數值的估計：參與實驗的這群TT隔空感應的成功率究竟有多少？論文提到事前期望十次之中至少有八次正確，也就是說成功率至少有80%或0.8。不過以Emily尚未進行第一次實驗的狀況，最合理的預測是找來的TT成功率從50%到100%都有可能。原因是之前的研究都沒有明確指出當時通過訓練的TT感應成功率是多少，Emily採用最保守的預測，以實驗結果估計的成功率有最高的可能性。要得知這個可能性有多高，必須將預測的成功率放入二項分佈進行模擬。示範如何模擬之前，我們先認識如何用均等分佈(uniform distribution)表達Emily第一次實驗之前的預測。 開啟機率模型的動畫網頁之前，我們先再次確認成功率是均等分佈的參數，範圍是0.5到1.0。因為均等分佈的數值均為整數，必須轉換才能得知Emily預測得到任何成功率的機率有多高。 打開uniform distribution預設畫面，你會看到最小值a到最大值b的連續數值的機率密度函數，在兩個參數a與b之間，所有數值的發生機率都是相等的。將a改成0，b改成6，兩個參數即可對應成功率50%與100%。機率密度函數一致指向0.167，也就是說50%到100%之間任意數值的出現機率，都是0.167。 我們當然可以運用模擬，看看各種成功率在10000次實驗結果出現的累積次數。雖然jamovi示範存檔有製造模擬結果的程式碼與輸出直方圖，因為目前jamovi中文顯示的支授還不夠完整，本書重製相同的直方圖於圖2.1。這張直方圖分割所有模擬數值到五個區域，所以每一個長方條的頂點都在2000左右。 圖 2.1: Emily Rosa第一次實驗的事前機率分配 jamovi示範存檔是使用jaomvi的計算變項(computed variable)製造模擬數據，讀者可檢視Aanlyses視窗TT_before_1st_success_rate欄位，了解欄位裡的每一個細格模擬成功率如何產生。從Emily規劃實驗的狀況來說，這些模擬數據顯示如果她真的做了一萬次實驗，每次實驗測得的成功率。 獲得真實資料後，成功率出現次數的機率將會改變。改變後的機率分配來自結合均等分佈與二項分佈的公式，所產生的模擬數據。之後每個單元介紹的統計方法，都是奠基於某種機率分佈的數學推導，而機率分配的模擬顯示判讀資料的正確方法。 2.1.5 事後機率分配：估計第一次測試的成功率 將一萬次模擬預測成功率，輸入二項分佈公式，將可以獲得事後機率分配的模擬結果。由於jamovi提供的模擬功能還沒有二項分佈公式，示範存檔的TT_1st_posterior是使用常態分佈公式模擬的數值，其中接近真實平均數(4.667)的數值，才是Emily想知道的測試結果。欄位TT_1st_post_success_rate根據TT_1st_posterior裡符合4與5之間的數值，篩選出TT_before_1st_success_rate的730筆成功率預測值，這些數值就是第一次測試事後機率分配。 專業統計論文將事前機率分配的通用數學符號寫成\\(P(\\theta)\\)，事後機率分配寫成\\(P(\\theta|D)\\)。羅馬字母\\(\\theta\\)表示要估計的參數，在這個案例裡就是成功率。大寫字母D就是從實際資料分析得到的資訊，在此就是Emily第一次實驗結算的平均正確率。示範存檔以直方圖呈現事後機率分配的趨勢，如圖2.2所示，次數最多的成功率在0.5到0.6之間，顯然與事前預測的成功率有不少差異。 圖 2.2: Emily Rosa第一次實驗結果的事後機率分配 至此我們已學到需要統計分析的問題，必須先選定正確的機率分佈呈現要估計或預測的參數。參數是我們運用收集到的資料，評估測量目標出現次數，進而推測事前估計或預測為真的可能性。統計實務裡，評估出現次數的工作是描述統計、推測可能性的工作是推論統計。深入探討Emily的研究細節，你應該對兩種工作有更進一步的體會：統計實務要取得有助結論的事後機率分配。有這樣的認識，就能理解任何需要統計分析的領域，必須先認識共同的基礎項目。事後機率是一種條件機率，我們要先知道一些基本的運算定理。 2.2 條件機率的計算與模擬 在此暫時放下Emily Rosa的案子，談一談二十世紀下半葉，美國統計學界提出的著名公案：蒙提霍爾問題(Steve, 1975)。蒙提霍爾是二十世紀六十年代著名的美國猜謎節目主持人，這個節目有個知名橋段：主持人向觀眾展示三道門，其中一道門之後是豪華轎車，另外兩道門之後是山羊。每集節目邀請來賓選出正確的門，選到車子現場直接開回家。不過這個橋段有個製造緊張氣氛的安排：來賓先指出其中一道門，接著主持人打開另外兩道門的其中一道，這道門之後一定是山羊。最後就是橋段的高潮，主持人給來賓一次機會，選擇一開始指出的門？還是選沒擇被打開的另一道門？ 統計學者與數學家最關心的是這個節目的來賓，選擇另一道門是車子的機率有沒有高於一開始選擇的門？這種情況就是條件機率的比較：已知其中一道門之後是山羊(B)，一開始指的門是車子(A)之機率。為了方便計算，一般寫成\\(P(A|B)\\)。同樣的道理，\\(P(\\bar{A}|B)\\)代表已知其中一道門之後是山羊(B)，另一道門是車子(\\(\\bar{A}\\))之機率。雖然\\(P(A|B)\\)與\\(P(\\bar{A}|B)\\)的總和是1，但是B也是一種機率事件，因為到底那道門之後是山羊，每一集節目都不會一樣。下表列出所有車子與山羊的情況： 狀況 1號門 2號門 3號門 A 車 羊 羊 B 羊 車 羊 C 羊 羊 車 節目主持人先讓來賓指出一道門，接著根據情況決定要打開那道門讓觀眾與來賓看山羊。例如車子在1號門之後的狀況，來賓先選擇1號門，接著主持人就隨機打開2號門或3號門；如果是車子不在1號門之後的狀況，來賓先選擇1號門，主持人接著就打開另一道是山羊的門。所以主持人要打開那道門讓觀眾看山羊，也是一種隨機事件。不過主持人打開那道門的機率，與來賓最後選那一道門中車子的機率無關。 讀者可以找到許多說明來賓最後該選那一道門的機率計算方法，不過我們都學過模擬機率的方法，將蒙提霍爾問題的來賓面對選擇的條件，轉化成R程式碼，就能得知上千次來賓都決定選擇另一道門，會中車子的機率。圖2.3來自蒙提霍爾問題jamovi範例，模擬一萬次來賓決定換門而贏得車子的次數與沒有贏得車子的次數。 圖 2.3: 蒙提霍爾問題一萬次模擬的事後機率分配 由模擬結果可知，換門而贏車的次數比換門而未贏車的次數高出一倍，也就是說\\(P(A|B)\\)約1/3，\\(P(\\bar{A}|B)\\)約2/3。如果使用機率原理計算，也會得到相同的結果。讀者也許看過其他計算的解說方法，在此我們要使用貝氏定理解說來賓換門贏車的條件機率的計算方法。 2.2.1 從蒙提霍爾問題理解貝氏定理 讀者也許曾經學過貝氏定理的公式，本書談到貝氏定理的地方都是使用以下公式： \\[ P(\\theta|D) = \\frac{P(D|\\theta) \\times P(\\theta)}{P(D)} \\] D表示資料，就像Emily Rosa的實驗結果；\\(\\theta\\)表示要估計的參數，或者理論的預測值，就像TT的感應成功率。 以蒙提霍爾問題的情境來說，D代表主持人打開有山羊的門，\\(\\theta\\)代表來賓換門贏車。我們表列來賓先選1號門，後來決定不選另一個門的各種結果，來說明如何利用貝氏定理計算不換門而贏車的事後機率。 狀況 1號門 2號門 3號門 結果 A 車 羊 羊 得車 B 羊 車 羊 得羊 C 羊 羊 車 得羊 如果來賓是研究者，\\(P(\\theta)\\)就是來賓一開始的理論預測成功的機率，上列表格得知三種狀況之中只有一種符合，所以\\(P(\\theta)\\)是1/3。而且不論來賓一開始選擇那道門，\\(P(\\theta)\\)都是1/3。 主持人打開後面是羊的門，就像研究者有了預測之後，根據理論收集的資料。來賓預期如果一開始選的門是對的，其餘兩個門會被主持人打開的機率應該是相等的。因此只以狀況A來說，主持人打開2號門或3號門的機率是一樣的，所以\\(P(D)\\)是1/2。因為是以來賓一開始的選擇決定狀況，所以任何狀況主持人會開那一道門的機率都是1/2。 在這場節目的狀況，\\(P(D|\\theta)\\)代表來賓應該考慮不論自己的猜測是否正確，主持人向觀眾開啟這道門的機率。如果一開始猜車子在1號門，主持人打開2號門可能是其中兩種狀況：第一種是狀況A，主持人可以打開2號門或3號門；第二種是狀況C，主持人能打開的只有2號門。不必考慮狀況B是因為車子在2號門之後，主持人不可能開門。所以如果一開始選擇1號門，接著主持人會打開2號門的狀況機率是相等的，也就是1/2。同樣的道理，主持人打開3號門的條件機率也是1/2。相同地，不論來賓一開始選那道門，來賓應考慮其餘的門被主持人打開的條件機率，一律是1/2。 在許多研究的狀況，\\(P(D|\\theta)\\)是根據理論的預測，能發現目前資料的條件機率。這是本書各單元範例與習題，所展示的資料之抽樣來源，本質是某種\\(P(D|\\theta)\\)的機率分配。心理學者廣泛使用統計方法之後，大部分學習內容奠基於這類條件機率。 以上三種機率代入貝氏定理的公式，就能得到來賓決定一開始選的門，能得到車子的機率是1/3。計算與模擬雖然得到相同答案，但是過程不相同，主要差異在於模擬不必考慮主持人的行動，只考慮來賓的最後選擇，也就是上述三種機率的總成。這也是為何jamovi範例的程式碼，只有模擬來賓的選擇與真正有車的門： # door number: 1,2,3 # Player&#39;s decision playerChoice &lt;- sample(1:3,1) # Where is the car prizeDoor &lt;- sample(1:3,1) 使用貝氏定理解說蒙提霍爾問題，我們可以發現來賓的猜測與最後不換門會得到車子機率都是1/3。如果這個節目都是採用這樣的遊戲流程，決定換門的來賓們大約每三位會有兩位會開車回家。以貝氏定理算出的事後機率，可做為下次研究的事前機率，很顯然參與蒙提霍爾節目的來賓，並不能靠過去的播出紀錄更新中獎機率。 註：蒙提霍爾問題的計算說明，改編自余海峯博士的直播錄影存檔：https://youtu.be/176RDyzlJck 2.2.2 使用事後機率推測TT的能力 科學研究的重要任務是以發現的結果更新事前的猜測，所以事後機率分配不同於事前預期的研究結果，才是真正有意義的科學研究。我們順此再談Emily Rosa測試TT感應成功率的研究，了解Emily第一次實驗結果如何更新她對TT能力的想法。 圖2.2呈現的事後機率分配，是來自Emily研究jamovi示範存檔的欄位TT_1st_post_success_rate，這個欄位正是以貝氏思維–或者說由貝氏定理發展出來的思考方法–產生的模擬資料，對應貝氏定理公式的\\(P(\\theta|D)\\)。存檔裡的另外兩個計算變項欄位TT_before_1st_success_rate與TT_1st_posterior，分別對應貝氏定理公式的\\(P(\\theta)\\)與\\(P(D|\\theta)\\)。至此你應該要問，怎麼沒有\\(P(D)\\)的機率分配？因為實際的研究收集到任何次數的資料可能性是一致的，在統計實務通常設定\\(P(D)\\)為1。實務如同示範存檔的設定，從\\(P(D|\\theta)\\)的機率分配選出匹配資料的數據，形成\\(P(\\theta|D)\\)的事後條件機率分配。\\(P(\\theta|D)\\)代表Emily完成第一次實驗之後，對於TT們真實能力的最新想法。 \\(P(\\theta|D)\\)機率分配有700筆數據，其中成功率大於80%的數據有5筆，所以Emily能從這群TT找到符合預期之人的機率大約是0.01。因為\\(P(\\theta|D)\\)是\\(P(D|\\theta)\\)的一部分，我們以符合預期成功率與資料平均數兩個條件，區分\\(P(D|\\theta)\\)模擬數據到如下表的四個種類。之後的單元，我們還會利用這張表理解假設檢定的運用原理： 不符合預期( &lt; 80% ) 符合預期( &gt; 80% ) 成功次數為4或5次 695 5 成功次數非4或5次 4246 3954 Emily在幾個月之後又找了13位TT再做一次研究。如何使用相同的方法分析第二次研究的資料，做出更新的結論？這就做為習題讓讀者自我學習，本章於總結統計學兩大流派後告一段落。 2.3 統計學兩大流派 Emily Rosa研究結果的jamovi示範存檔報表最後部分呈現第一次研究結果的平均值與標準差等資訊，這些資訊是使用jamovi的描述統計模組Exploration，分析Emily_1st欄位的結果，也是原始論文表格呈現的資訊。這份報表是示範裡唯一呈現描述統計的部分，而平均數資訊提供事後機率分配TT_1st_post_success_rate的數據挑選範圍。由此我們可以分辨描述統計(descriptive statistics)與推論統計(inference statistics)的功能：描述統計集合各種呈現資料中“可推論資訊”的技巧，以適當的測量尺度呈現資料的集中與變異。推論統計評估“可推論資訊”符合預測的可能性，或者值得再做探討的價值。 現代統計學的發展歷史與心理學等需要分析資料的科學領域相輔相成。首先被廣泛使用的推論統計方法需要的計算資源較少，這個單元示範的機率分配模擬，直到十幾年前才開始在個人電腦實現，所以需要較多計算資源的統計方法能被更多人使用。Emily Rosa研究結果的示範分析是一種貝氏統計(Bayesian Statistics)的展示，而本書各單元主要介紹的是次數主義統計(Frequenitist Statistics)。 2.3.1 次數主義統計 這個單元的TT感應研究示範存檔與蒙提霍爾問題示範存檔都有模擬機率分配的部分，模擬方式都是累積一萬次實驗結果，以多次實驗累積的機率分配推論資訊，正是次數主義的中心思想。所有研究問題都有一個最適合的機率分佈，只要能用最接近的機率分配評估資料出現的機率，就能用最適合的統計方法。 許多研究問題的機率分配是總計根據某種假設，當前資料的發生次數，也就是前面討論貝氏定理時提到的\\(P(D|\\theta)\\)。許多次數主義統計方法原理是建立在這種條件機率分配，但是研究者不必製造模擬數據，只要確定收集資料的條件符合要素，\\(P(D|\\theta)\\)必定接近預設的機率分佈，通常是常態分佈(Normal Distribution)。常見的要素有常態性(Normality)與等變異性(Equal variance)，統計學家也開發許多方法，幫助研究者確認手上的資料符合這些要素，讓研究者能合理運用統計方法得到的資訊推論。 然而包括心理學在內的多數社會科學研究者，在學習次數主義統計方法的過程中並未充分理解\\(P(D|\\theta)\\)不等於真正想研究的\\(P(\\theta)\\)，近幾年更導致全面更改使用統計方法慣例的議論四起(Benjamin et al., 2017, Lakens et al. (2018))。次數主義統計方法雖然是本書的學習重點，我會在每個範例提示使用建議。 2.3.2 貝氏統計 貝氏統計不必設定\\(P(D|\\theta)\\)符合那一種機率分佈，而是設定\\(P(\\theta)\\)符合的機率分佈，運用現有資料及模擬程序製造\\(P(D|\\theta)\\)的機率分配，以此得出的\\(P(\\theta|D)\\)機率分配用於推測資料意義或投入下一輪資料分析。因為真實的心理學研究課題包含許多變項，模擬程序需要複雜的演算法與計算資源，目前最常被應用的演算法是馬可夫蒙地卡羅方法(Markov chain Monte Carlo,簡稱MCMC)。 兩大流派的共同點是能用統計方法處理的資料必須是透過隨機程序所得，像是調查使用的抽樣，還有實驗的分派，\\(P(D|\\theta)\\)才能符合方法原理的設定或可用演算法進行數據模擬。由於兩大流派的差異是處理\\(P(D|\\theta)\\)的方式，所以每種已經發展成熟的次數主義統計方法都有對應的貝氏統計方法。本書設定讀者是統計初學者，不會直接介紹貝氏統計方法，每個介紹統計方法的單元最後，都會簡介貝氏統計方法的學習資源。 2.4 習題 Emily Rosa完成第一次研究之後，應採訪記者的請求，找了包括曾參與第一次研究的7位TT等13名受測者。這13位各自接受十次測試的正確次數是1,3,3,3,3,4,4,4,4,5,5,7,7。請以第一次研究之後更新的事後機率分配做為第二次的事前預測，製作第二次研究的事後機率分配模擬數據，以此判斷Emily Rosa能找到的TT有至少80%成功率的可能性。 參考文獻 "]
]
